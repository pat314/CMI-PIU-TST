{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div\r\n      style=\"\r\n        text-align: center;\r\n        font-weight: bold;\r\n        font-size: 32px;\r\n        font-family: Arial, Helvetica, sans-serif;\r\n        color: white;\r\n        background-color: rgb(84, 84, 84);\r\n        padding-top: 20px;\r\n        padding-bottom: 20px;\r\n        border-radius: 20px;\r\n      \"\r\n    >\r\n      CMI | Problematic Internet Use\r\n    </div>","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport optuna\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tqdm import tqdm\nfrom scipy.optimize import minimize\nfrom IPython.display import clear_output\nimport concurrent.futures\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom sklearn.base import clone\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nN_FOLD = 5\nSEED = 42\n\noptuna.logging.set_verbosity(optuna.logging.WARNING)\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:55:57.803452Z","iopub.execute_input":"2024-12-17T11:55:57.803839Z","iopub.status.idle":"2024-12-17T11:56:03.132635Z","shell.execute_reply.started":"2024-12-17T11:55:57.803792Z","shell.execute_reply":"2024-12-17T11:56:03.131702Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Process data","metadata":{}},{"cell_type":"code","source":"TRAIN_PARQUET_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\"\nTEST_PARQUET_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\"\nTRAIN_CSV_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\"\nTEST_CSV_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\"\nSAMPLE_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv\"\nDICTIONARY_PATH = \"/kaggle/input/child-mind-institute-problematic-internet-use/data_dictionary.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.134112Z","iopub.execute_input":"2024-12-17T11:56:03.134584Z","iopub.status.idle":"2024-12-17T11:56:03.142158Z","shell.execute_reply.started":"2024-12-17T11:56:03.134559Z","shell.execute_reply":"2024-12-17T11:56:03.139693Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Time series data","metadata":{}},{"cell_type":"code","source":"def process_time_series(file_path: str) -> list:\n    df = pd.read_parquet(file_path)\n    df = df.drop(\"step\", axis=1)\n    return df.describe().values.flatten().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.143857Z","iopub.execute_input":"2024-12-17T11:56:03.144705Z","iopub.status.idle":"2024-12-17T11:56:03.173092Z","shell.execute_reply.started":"2024-12-17T11:56:03.144673Z","shell.execute_reply":"2024-12-17T11:56:03.170972Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_time_series(dir: str) -> pd.DataFrame:\n    all_parquet_folders = os.listdir(dir)\n    all_ids = [file.split(\"=\")[-1] for file in all_parquet_folders]\n    all_parquet_files = [\n        os.path.join(dir, folder_name, \"part-0.parquet\")\n        for folder_name in all_parquet_folders\n    ]\n\n    with ThreadPoolExecutor(max_workers=4) as excuter:\n        results = list(\n            tqdm(\n                excuter.map(process_time_series, all_parquet_files), total=len(all_ids)\n            )\n        )\n\n    df = pd.DataFrame(results)\n    df.columns = [f\"Stat_{i}\" for i in range(len(results[0]))]\n    df[\"id\"] = all_ids\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.175339Z","iopub.execute_input":"2024-12-17T11:56:03.175624Z","iopub.status.idle":"2024-12-17T11:56:03.193472Z","shell.execute_reply.started":"2024-12-17T11:56:03.175600Z","shell.execute_reply":"2024-12-17T11:56:03.192169Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class AutoEncoder(nn.Module):\n    def __init__(self, input_dim, encoding_dim):\n        super(AutoEncoder, self).__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, encoding_dim*3),\n            nn.ReLU(),\n            nn.Linear(encoding_dim*3, encoding_dim*2),\n            nn.ReLU(),\n            nn.Linear(encoding_dim*2, encoding_dim),\n            nn.ReLU()\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(encoding_dim, input_dim*2),\n            nn.ReLU(),\n            nn.Linear(input_dim*2, input_dim*3),\n            nn.ReLU(),\n            nn.Linear(input_dim*3, input_dim),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.194603Z","iopub.execute_input":"2024-12-17T11:56:03.194902Z","iopub.status.idle":"2024-12-17T11:56:03.211060Z","shell.execute_reply.started":"2024-12-17T11:56:03.194879Z","shell.execute_reply":"2024-12-17T11:56:03.209808Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def encode_time_series(\n    df: pd.DataFrame, encoding_dim: int, batch_size: int, epochs: int\n) -> pd.DataFrame:\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    data = torch.FloatTensor(df)\n    input_dim = data.shape[1]\n    autoencoder = AutoEncoder(input_dim, encoding_dim)\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(autoencoder.parameters())\n\n    for epoch in range(epochs):\n        for i in range(0, len(data), batch_size):\n            batch = data[i : i + batch_size]\n            optimizer.zero_grad()\n            reconstructed = autoencoder(batch)\n            loss = criterion(reconstructed, batch)\n            loss.backward()\n            optimizer.step()\n\n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]\")\n\n    with torch.no_grad():\n        encoded_data = autoencoder.encoder(data).numpy()\n\n    df_encoded = pd.DataFrame(\n        encoded_data, columns=[f\"Enc_{i + 1}\" for i in range(encoded_data.shape[1])]\n    )\n\n    return df_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.212517Z","iopub.execute_input":"2024-12-17T11:56:03.212809Z","iopub.status.idle":"2024-12-17T11:56:03.232123Z","shell.execute_reply.started":"2024-12-17T11:56:03.212786Z","shell.execute_reply":"2024-12-17T11:56:03.231272Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## CSV data","metadata":{}},{"cell_type":"code","source":"def map_seasons(df: pd.DataFrame) -> pd.DataFrame:\n    # 10 columns (excluding PCIAT_Season)\n    season_cols = [\n        \"Basic_Demos-Enroll_Season\",\n        \"CGAS-Season\",\n        \"Physical-Season\",\n        \"Fitness_Endurance-Season\",\n        \"FGC-Season\",\n        \"BIA-Season\",\n        \"PAQ_A-Season\",\n        \"PAQ_C-Season\",\n        \"SDS-Season\",\n        \"PreInt_EduHx-Season\",\n    ]\n\n    df = df.drop(columns=[col for col in df.columns if \"PCIAT\" in col])\n\n    mapping = {\"Summer\": 0, \"Winter\": 1, \"Spring\": 2, \"Fall\": 3, \"Missing\": 4}\n\n    for col in season_cols:\n        df[col] = df[col].fillna(\"Missing\")\n        df[col] = df[col].map(mapping).astype(int)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.233411Z","iopub.execute_input":"2024-12-17T11:56:03.233704Z","iopub.status.idle":"2024-12-17T11:56:03.250782Z","shell.execute_reply.started":"2024-12-17T11:56:03.233674Z","shell.execute_reply":"2024-12-17T11:56:03.249856Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n    # season_cols = [col for col in df.columns if 'Season' in col]\n    # df = df.drop(season_cols, axis=1) \n    # df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n    # df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n    # df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n    # df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n    # df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n    # df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n    # df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n    # df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n    # df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n    # df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n    # df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n    # df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n    # df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n    # df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n    # df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n    # df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.251797Z","iopub.execute_input":"2024-12-17T11:56:03.252029Z","iopub.status.idle":"2024-12-17T11:56:03.273647Z","shell.execute_reply.started":"2024-12-17T11:56:03.252007Z","shell.execute_reply":"2024-12-17T11:56:03.272613Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"def compute_qwk(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n    return cohen_kappa_score(y_pred, y_true,weights=\"quadratic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.275026Z","iopub.execute_input":"2024-12-17T11:56:03.275521Z","iopub.status.idle":"2024-12-17T11:56:03.293223Z","shell.execute_reply.started":"2024-12-17T11:56:03.275470Z","shell.execute_reply":"2024-12-17T11:56:03.291938Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def round_prediction(y_pred: np.ndarray, thresholds: list) -> np.ndarray:\n\n    return np.where(\n        y_pred < thresholds[0],\n        0,\n        np.where(y_pred < thresholds[1], 1, np.where(y_pred < thresholds[2], 2, 3)),\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.296206Z","iopub.execute_input":"2024-12-17T11:56:03.296563Z","iopub.status.idle":"2024-12-17T11:56:03.318971Z","shell.execute_reply.started":"2024-12-17T11:56:03.296537Z","shell.execute_reply":"2024-12-17T11:56:03.317221Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate_predictions(thresholds, y_true, y_pred):\n    rounded_pred = round_prediction(y_pred, thresholds)\n    return -compute_qwk(y_true, rounded_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.320319Z","iopub.execute_input":"2024-12-17T11:56:03.320687Z","iopub.status.idle":"2024-12-17T11:56:03.334690Z","shell.execute_reply.started":"2024-12-17T11:56:03.320649Z","shell.execute_reply":"2024-12-17T11:56:03.333534Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_model(\n    train_set: pd.DataFrame, test_set: pd.DataFrame, model, test_id\n) -> pd.DataFrame:\n    x = train_set.drop(\"sii\", axis=1)\n    y = train_set[\"sii\"]\n\n    n_samples = len(y)\n\n    SKF = StratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=SEED)\n\n    train_kappa_scores = []\n    val_kappa_scores = []\n\n    non_rounded_train_pred = np.zeros(n_samples, dtype=float)\n    non_rounded_test_pred = np.zeros((len(test_set), N_FOLD), dtype=float)\n\n    for fold, (train_index, val_index) in enumerate(SKF.split(x, y)):\n        train_data, val_data = x.iloc[train_index], x.iloc[val_index]\n        train_label, val_label = y.iloc[train_index], y.iloc[val_index]\n\n        clone_model = clone(model)\n        clone_model.fit(train_data, train_label)\n\n        train_pred = clone_model.predict(train_data)\n        val_pred = clone_model.predict(val_data)\n\n        train_kappa_scores.append(\n            compute_qwk(train_pred.round(0).astype(int), train_label)\n        )\n\n        val_kappa_scores.append(\n            compute_qwk(val_pred.round(0).astype(int), val_label)\n        )\n\n        non_rounded_train_pred[val_index] = val_pred\n        non_rounded_test_pred[:, fold] = clone_model.predict(test_set)\n\n    kappa_optimizer = minimize(\n        evaluate_predictions,\n        x0=[0.5, 1.5, 2.5],\n        args=(y, non_rounded_train_pred),\n        method=\"Nelder-Mead\",\n    )\n\n    optimized_thresholds = kappa_optimizer.x\n    rounded_train_pred = round_prediction(non_rounded_train_pred, optimized_thresholds)\n    optimized_train_kappa_score = compute_qwk(rounded_train_pred, y)\n\n    print(\"Optimized train kappa score:\", optimized_train_kappa_score)\n\n    rounded_test_pred = round_prediction(\n        non_rounded_test_pred.mean(axis=1), optimized_thresholds\n    )\n\n    submisison = pd.DataFrame({\"id\": test_id, \"sii\": rounded_test_pred})\n\n    return (submisison, optimized_train_kappa_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.335738Z","iopub.execute_input":"2024-12-17T11:56:03.336454Z","iopub.status.idle":"2024-12-17T11:56:03.355166Z","shell.execute_reply.started":"2024-12-17T11:56:03.336388Z","shell.execute_reply":"2024-12-17T11:56:03.354301Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# Load and encode time series data\ntrain_ts = load_time_series(TRAIN_PARQUET_PATH)\ntest_ts = load_time_series(TEST_PARQUET_PATH)\nencoded_train_ts = encode_time_series(\n    df=train_ts.drop(\"id\", axis=1), encoding_dim=60, batch_size=32, epochs=150\n)\nencoded_test_ts = encode_time_series(\n    df=test_ts.drop(\"id\", axis=1), encoding_dim=60, batch_size=32, epochs=150\n)\nencoded_train_ts[\"id\"] = train_ts[\"id\"]\nencoded_test_ts[\"id\"] = test_ts[\"id\"]\n\n# Load and process csv data\ntrain_csv = pd.read_csv(TRAIN_CSV_PATH)\ntest_csv = pd.read_csv(TEST_CSV_PATH)\nmapped_train_csv = map_seasons(train_csv.drop(\"id\", axis=1))\nmapped_test_csv = map_seasons(test_csv.drop(\"id\", axis=1))\n\nknn_imputer = KNNImputer(n_neighbors=5)\nmask_train = mapped_train_csv.notna()\nmask_test = mapped_test_csv.notna()\n\nimputed_train_csv = pd.DataFrame(\n    knn_imputer.fit_transform(mapped_train_csv),\n    columns=mapped_train_csv.columns\n)\n\nimputed_test_csv = pd.DataFrame(\n    knn_imputer.fit_transform(mapped_test_csv),\n    columns=mapped_test_csv.columns\n)\n\nimputed_train_csv[mask_train] = mapped_train_csv[mask_train]\nimputed_test_csv[mask_test] = mapped_test_csv[mask_test]\n\nimputed_train_csv[\"sii\"] = imputed_train_csv[\"sii\"].round(0).astype(int)\n\nimputed_train_csv[\"id\"] = train_csv[\"id\"]\nimputed_test_csv[\"id\"] = test_csv[\"id\"]\n\n# Merge csv and time series data\ntrain = pd.merge(imputed_train_csv, encoded_train_ts, how=\"left\", on=\"id\")\ntest = pd.merge(imputed_test_csv, encoded_test_ts, how=\"left\", on=\"id\")\n\ntrain_id = train[\"id\"]\ntest_id = test[\"id\"]\n\ntrain = train.drop(\"id\", axis=1)\ntest = test.drop(\"id\", axis=1)\n\n# Do feature engineering\ntrain = feature_engineering(train)\ntest = feature_engineering(test)\n\nif np.any(np.isinf(train)):\n    train = train.replace([np.inf, -np.inf], np.nan)\n\n# train = train.iloc[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:03.356890Z","iopub.execute_input":"2024-12-17T11:56:03.357333Z","iopub.status.idle":"2024-12-17T11:57:43.919456Z","shell.execute_reply.started":"2024-12-17T11:56:03.357297Z","shell.execute_reply":"2024-12-17T11:57:43.916823Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 996/996 [01:16<00:00, 13.04it/s]\n100%|██████████| 2/2 [00:00<00:00, 10.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/150], Loss: 1.6039]\nEpoch [20/150], Loss: 1.5405]\nEpoch [30/150], Loss: 1.4856]\nEpoch [40/150], Loss: 1.4620]\nEpoch [50/150], Loss: 1.4509]\nEpoch [60/150], Loss: 1.4502]\nEpoch [70/150], Loss: 1.4728]\nEpoch [80/150], Loss: 1.4621]\nEpoch [90/150], Loss: 1.3947]\nEpoch [100/150], Loss: 1.3611]\nEpoch [110/150], Loss: 1.3599]\nEpoch [120/150], Loss: 1.3612]\nEpoch [130/150], Loss: 1.3637]\nEpoch [140/150], Loss: 1.3445]\nEpoch [150/150], Loss: 1.3371]\nEpoch [10/150], Loss: 1.0062]\nEpoch [20/150], Loss: 0.7385]\nEpoch [30/150], Loss: 0.4348]\nEpoch [40/150], Loss: 0.4271]\nEpoch [50/150], Loss: 0.4271]\nEpoch [60/150], Loss: 0.4271]\nEpoch [70/150], Loss: 0.4271]\nEpoch [80/150], Loss: 0.4271]\nEpoch [90/150], Loss: 0.4271]\nEpoch [100/150], Loss: 0.4271]\nEpoch [110/150], Loss: 0.4271]\nEpoch [120/150], Loss: 0.4271]\nEpoch [130/150], Loss: 0.4271]\nEpoch [140/150], Loss: 0.4271]\nEpoch [150/150], Loss: 0.4271]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Find optimal parameters for models","metadata":{}},{"cell_type":"code","source":"# def objective_xgb(trial):\n#     params = {\n#         'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n#         'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n#         'gamma': trial.suggest_float('gamma', 0, 5),\n#         'lambda': trial.suggest_float('lambda', 1e-3, 10, log=True),\n#     }\n    \n#     model = XGBRegressor(**params, verbosity=0, device=\"cuda\")\n#     _, metric = train_model(train, test, model, test_id)\n    \n#     return metric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:43.922461Z","iopub.execute_input":"2024-12-17T11:57:43.922980Z","iopub.status.idle":"2024-12-17T11:57:43.930929Z","shell.execute_reply.started":"2024-12-17T11:57:43.922935Z","shell.execute_reply":"2024-12-17T11:57:43.929594Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# def objective_catb(trial):\n#     params = {\n#         'depth': trial.suggest_int('depth', 3, 10),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n#         'iterations': trial.suggest_int('iterations', 50, 500),\n#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n#     }\n    \n#     model = CatBoostRegressor(**params, verbose=0, task_type='GPU')\n#     _, metric = train_model(train, test, model, test_id)\n    \n#     return metric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:43.933989Z","iopub.execute_input":"2024-12-17T11:57:43.934632Z","iopub.status.idle":"2024-12-17T11:57:43.960387Z","shell.execute_reply.started":"2024-12-17T11:57:43.934602Z","shell.execute_reply":"2024-12-17T11:57:43.959097Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# def objective_lgbm(trial):\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n#         'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n#     }\n    \n#     model = LGBMRegressor(**params, verbose=-1, device=\"GPU\")\n#     _, metric = train_model(train, test, model, test_id)\n    \n#     return metric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:43.962105Z","iopub.execute_input":"2024-12-17T11:57:43.962531Z","iopub.status.idle":"2024-12-17T11:57:43.978648Z","shell.execute_reply.started":"2024-12-17T11:57:43.962500Z","shell.execute_reply":"2024-12-17T11:57:43.977542Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# study_xgb = optuna.create_study(direction='maximize')\n# study_catb = optuna.create_study(direction='maximize')\n# study_lgbm = optuna.create_study(direction='maximize')\n\n# def optimize_study(study, objective, n_trials=50):\n#     study.optimize(objective, n_trials=n_trials)\n\n# with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n#     futures = [\n#         executor.submit(optimize_study, study_xgb, objective_xgb),\n#         executor.submit(optimize_study, study_catb, objective_catb),\n#         executor.submit(optimize_study, study_lgbm, objective_lgbm)\n#     ]\n#     concurrent.futures.wait(futures)\n\n# BEST_PARAMS_XGB = study_xgb.best_params\n# BEST_PARAMS_CATB = study_catb.best_params\n# BEST_PARAMS_LGBM = study_lgbm.best_params\n\n# clear_output(wait=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:43.979910Z","iopub.execute_input":"2024-12-17T11:57:43.980220Z","iopub.status.idle":"2024-12-17T11:57:44.010343Z","shell.execute_reply.started":"2024-12-17T11:57:43.980192Z","shell.execute_reply":"2024-12-17T11:57:44.008386Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# print(BEST_PARAMS_XGB)\n# print(BEST_PARAMS_CATB)\n# print(BEST_PARAMS_LGBM)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.013110Z","iopub.execute_input":"2024-12-17T11:57:44.013664Z","iopub.status.idle":"2024-12-17T11:57:44.025389Z","shell.execute_reply.started":"2024-12-17T11:57:44.013626Z","shell.execute_reply":"2024-12-17T11:57:44.024281Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"XGB: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.032806306822661946, 'n_estimators': 124, 'subsample': 0.7612200524957443, 'colsample_bytree': 0.7879462813404031, 'gamma': 2.27693382985497, 'lambda': 0.0037960352854142705}\n\nCATB: {'depth': 8, 'learning_rate': 0.02999839537419576, 'iterations': 492, 'l2_leaf_reg': 2.3005068330449827}\n\nLGBM: {'num_leaves': 290, 'learning_rate': 0.022351630623035076, 'n_estimators': 110, 'min_child_samples': 36, 'subsample': 0.64715318375847, 'colsample_bytree': 0.5964597906674066, 'reg_alpha': 1.5700746777921748, 'reg_lambda': 2.718790747208782}","metadata":{}},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"BEST_PARAMS_XGB = {\n    \"booster\": \"gbtree\",\n    \"max_depth\": 5,\n    \"learning_rate\": 0.032806306822661946,\n    \"n_estimators\": 124,\n    \"subsample\": 0.7612200524957443,\n    \"colsample_bytree\": 0.7879462813404031,\n    \"gamma\": 2.27693382985497,\n    \"lambda\": 0.0037960352854142705,\n    \"verbosity\": 0,\n}\n\nBEST_PARAMS_CATB = {\n    \"depth\": 8,\n    \"learning_rate\": 0.02999839537419576,\n    \"iterations\": 492,\n    \"l2_leaf_reg\": 2.3005068330449827,\n    \"verbose\": 0,\n}\n\nBEST_PARAMS_LGBM = {\n    \"num_leaves\": 290,\n    \"learning_rate\": 0.022351630623035076,\n    \"n_estimators\": 110,\n    \"min_child_samples\": 36,\n    \"subsample\": 0.64715318375847,\n    \"colsample_bytree\": 0.5964597906674066,\n    \"reg_alpha\": 1.5700746777921748,\n    \"reg_lambda\": 2.718790747208782,\n    \"verbosity\": -1,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.046143Z","iopub.execute_input":"2024-12-17T11:57:44.046515Z","iopub.status.idle":"2024-12-17T11:57:44.067956Z","shell.execute_reply.started":"2024-12-17T11:57:44.046487Z","shell.execute_reply":"2024-12-17T11:57:44.066708Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# def objective_ensemble(trial):\n#     weights = {\n#         \"weights\": [\n#             trial.suggest_float(\"weight_xgb\", 0.0, 10.0),\n#             trial.suggest_float(\"weight_catb\", 0.0, 10.0),\n#             trial.suggest_float(\"weight_lgbm\", 0.0, 10.0),\n#         ]\n#     }\n    \n#     model = VotingRegressor(estimators=[\n#         (\"xgb\", XGBRegressor(**BEST_PARAMS_XGB, device=\"cuda\")),\n#         (\"catb\", CatBoostRegressor(**BEST_PARAMS_CATB, task_type=\"GPU\")),\n#         (\"lgbm\", LGBMRegressor(**BEST_PARAMS_LGBM, device=\"GPU\")),\n#     ], **weights)\n    \n#     _, metric = train_model(train, test, model, test_id)\n    \n#     return metric\n\n\n# study_ensemble = optuna.create_study(direction='maximize')\n\n# def optimize_study(study, objective, n_trials=50):\n#     study.optimize(objective, n_trials=n_trials)\n\n# with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n#     futures = [\n#         executor.submit(optimize_study, study_ensemble, objective_ensemble)\n#     ]\n#     concurrent.futures.wait(futures)\n\n# BEST_WEIGHTS = study_ensemble.best_params\n\n# clear_output(wait=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.069255Z","iopub.execute_input":"2024-12-17T11:57:44.069618Z","iopub.status.idle":"2024-12-17T11:57:44.084705Z","shell.execute_reply.started":"2024-12-17T11:57:44.069587Z","shell.execute_reply":"2024-12-17T11:57:44.083288Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# print(BEST_WEIGHTS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.086693Z","iopub.execute_input":"2024-12-17T11:57:44.087205Z","iopub.status.idle":"2024-12-17T11:57:44.112771Z","shell.execute_reply.started":"2024-12-17T11:57:44.087176Z","shell.execute_reply":"2024-12-17T11:57:44.111703Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"{'weight_xgb': 0.29143842381072055, 'weight_catb': 0.7223070202458827, 'weight_lgbm': 0.0038376523038045}","metadata":{}},{"cell_type":"code","source":"ensemble_model = VotingRegressor(estimators=[\n    (\"xgb\", XGBRegressor(**BEST_PARAMS_XGB)),\n    (\"catb\", CatBoostRegressor(**BEST_PARAMS_CATB)),\n    (\"lgbm\", LGBMRegressor(**BEST_PARAMS_LGBM)),\n], weights=[0.29143842381072055, 0.7223070202458827, 0.0038376523038045])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.114127Z","iopub.execute_input":"2024-12-17T11:57:44.114443Z","iopub.status.idle":"2024-12-17T11:57:44.134490Z","shell.execute_reply.started":"2024-12-17T11:57:44.114413Z","shell.execute_reply":"2024-12-17T11:57:44.133228Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"submission, _ = train_model(train, test, ensemble_model, test_id)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nclear_output(wait=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:57:44.135893Z","iopub.execute_input":"2024-12-17T11:57:44.136321Z","iopub.status.idle":"2024-12-17T11:59:02.513371Z","shell.execute_reply.started":"2024-12-17T11:57:44.136228Z","shell.execute_reply":"2024-12-17T11:59:02.511776Z"}},"outputs":[{"name":"stdout","text":"Optimized train kappa score: 0.48975690655504844\n","output_type":"stream"}],"execution_count":24}]}